{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!mkdir {HOME}/datasets\n",
        "%cd {HOME}/datasets\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\" YOUR_KEY\")\n",
        "project = rf.workspace(\"wilgvalz\").project(\"game_unity_detect\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov7\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8N3RDfdS9-u",
        "outputId": "3cfb1351-0aea-4fa0-9088-0e5f709d27eb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘{HOME}/datasets’: No such file or directory\n",
            "[Errno 2] No such file or directory: '{HOME}/datasets'\n",
            "/content\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Game_unity_Detect-1 to yolov7pytorch:: 100%|██████████| 4839/4839 [00:00<00:00, 12658.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Game_unity_Detect-1 in yolov7pytorch:: 100%|██████████| 294/294 [00:00<00:00, 4328.26it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Обучение SDD модели на датасете для Object Detection. Датасет собран вручную.\n",
        "#Содержит 5 классов (мною были выбраны 5 жестов рук), разметка\n",
        "#bounding boxes проведена при помощи roboflow\n",
        "#цель - демонстрационная, а не высокая точность"
      ],
      "metadata": {
        "id": "JGVoQRnZQ8Bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir('/content/Game_unity_Detect-1/train/images')[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K0M8Ek4D7qVA",
        "outputId": "88c117ec-78b5-4cf4-de73-64e769235deb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'no-98d5ec00-459b-11ef-8594-9801a7964a15_jpg.rf.ef486ff24c22578a73add9eedc04bbb8.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = os.listdir('/content/Game_unity_Detect-1/train/images')"
      ],
      "metadata": {
        "id": "IZ35cwsv7qad"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "idx = []\n",
        "for i in range(len(imgs)):\n",
        "  idx.append(re.match('.*?(?=\\.jpg)', imgs[i]).group(0))"
      ],
      "metadata": {
        "id": "LFsSfpO9B5ri"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4vJr9eOCF4M",
        "outputId": "51cad5c4-9508-4c15-e9c9-897e1ed89e4b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['no-98d5ec00-459b-11ef-8594-9801a7964a15_jpg.rf.ef486ff24c22578a73add9eedc04bbb8',\n",
              " 'no-9c976684-459b-11ef-8594-9801a7964a15_jpg.rf.ad4ca59f59963f81149a3bde2ae7ad68',\n",
              " 'iloveyou-adefd920-459b-11ef-8594-9801a7964a15_jpg.rf.3bcc96a9c1bf9e7a693c1f3cf947fb9c',\n",
              " 'hello-5721e32c-459b-11ef-8594-9801a7964a15_jpg.rf.111ac037aacccfc65fe0003bf2e1b53f',\n",
              " 'yes-83c24ff2-459b-11ef-8594-9801a7964a15_jpg.rf.a8eaf93d71a14f5ee8d8c8bfc27cecd9',\n",
              " 'yes-88c1b79a-459b-11ef-8594-9801a7964a15_jpg.rf.29f1f0b810a3a41de9425ca05a12913a',\n",
              " 'yes-83c24ff2-459b-11ef-8594-9801a7964a15_jpg.rf.9fd4c2a21b9187f08ee20d5373774fcf',\n",
              " 'thanks-6d786808-459b-11ef-8594-9801a7964a15_jpg.rf.e97dd67bf737754814e1052f82ca0789',\n",
              " 'iloveyou-a7a85efc-459b-11ef-8594-9801a7964a15_jpg.rf.f01e9a5c48964f25ae9e4875c994219d',\n",
              " 'iloveyou-a8e838aa-459b-11ef-8594-9801a7964a15_jpg.rf.fe229b589b299a71334135018238b50b',\n",
              " 'thanks-6d786808-459b-11ef-8594-9801a7964a15_jpg.rf.9ef9c09f2b9a8427946869fb33aa9f98',\n",
              " 'thanks-74fa00aa-459b-11ef-8594-9801a7964a15_jpg.rf.0a26eeefe54dde87310368cd1a120e4f',\n",
              " 'iloveyou-a7a85efc-459b-11ef-8594-9801a7964a15_jpg.rf.907c748700960b13b5820d1d7ac18884',\n",
              " 'no-9294a66a-459b-11ef-8594-9801a7964a15_jpg.rf.12829c9b41b68017e14d50cf5f309622',\n",
              " 'no-98d5ec00-459b-11ef-8594-9801a7964a15_jpg.rf.bcd2361abbcc09729bdf84615eb9930e',\n",
              " 'no-901a5df8-459b-11ef-8594-9801a7964a15_jpg.rf.2b24b2e37348b9a1d6b8e74435875146',\n",
              " 'no-9f0f7d84-459b-11ef-8594-9801a7964a15_jpg.rf.f6b69068a1d76539a619d8aa5de63fef',\n",
              " 'thanks-73bacfa8-459b-11ef-8594-9801a7964a15_jpg.rf.e9696d9fc12a861fab3ccfb047ef471e',\n",
              " 'yes-80067cf8-459b-11ef-8594-9801a7964a15_jpg.rf.a4f9ba0b4f8df17b15404d90708a3926',\n",
              " 'hello-5ea2fa28-459b-11ef-8594-9801a7964a15_jpg.rf.6b3abb28d86ba29fc03375ec37043a1e',\n",
              " 'yes-79c8ae6a-459b-11ef-8594-9801a7964a15_jpg.rf.7b71acae0123470ba4c4621bb066c85f',\n",
              " 'iloveyou-adefd920-459b-11ef-8594-9801a7964a15_jpg.rf.de7b5f88035c0b0d53e13ab1326f5acf',\n",
              " 'iloveyou-a7a85efc-459b-11ef-8594-9801a7964a15_jpg.rf.ab4db1c3caaf88cf3e4548daa1dcb9ff',\n",
              " 'hello-5ae2055a-459b-11ef-8594-9801a7964a15_jpg.rf.04f154ba62e65cf4d999a00d949e0b16',\n",
              " 'iloveyou-adefd920-459b-11ef-8594-9801a7964a15_jpg.rf.67ab60b9c7f14dcacd5039dc12f14ea6',\n",
              " 'iloveyou-b1ba006c-459b-11ef-8594-9801a7964a15_jpg.rf.55739cf720becef349b7032ff6b82419',\n",
              " 'yes-88c1b79a-459b-11ef-8594-9801a7964a15_jpg.rf.327a1ec212eeee89be00af457a939df3',\n",
              " 'no-9515fc72-459b-11ef-8594-9801a7964a15_jpg.rf.1c944c4b43a59e5dd92dedb724864c25',\n",
              " 'thanks-73bacfa8-459b-11ef-8594-9801a7964a15_jpg.rf.914df2a99cde064f740456b6f2ae7487',\n",
              " 'yes-8b432148-459b-11ef-8594-9801a7964a15_jpg.rf.3d3369a0b0209cd7fcbf5c91cf4e8061',\n",
              " 'iloveyou-acadddd2-459b-11ef-8594-9801a7964a15_jpg.rf.144cac3639eb45d05ddaa2408b0d1390',\n",
              " 'iloveyou-ab6839c2-459b-11ef-8594-9801a7964a15_jpg.rf.db0ad79d5ed36981f8f9894e271ac880',\n",
              " 'no-9b57294e-459b-11ef-8594-9801a7964a15_jpg.rf.2ee7656fca4e18d5fbf014a0fba8dedf',\n",
              " 'yes-83c24ff2-459b-11ef-8594-9801a7964a15_jpg.rf.62bbf31fe6d366ab73c71c7076c4e2a4',\n",
              " 'no-9dce4ab8-459b-11ef-8594-9801a7964a15_jpg.rf.996e59d900917dec4a0530c8b5bc64b4',\n",
              " 'no-9a168f48-459b-11ef-8594-9801a7964a15_jpg.rf.5fbfc327c9878fdaef613f12a2841468',\n",
              " 'iloveyou-b7f903ce-459b-11ef-8594-9801a7964a15_jpg.rf.8bf63ce25e1076318ed07d8333d7d005',\n",
              " 'no-9b57294e-459b-11ef-8594-9801a7964a15_jpg.rf.4428d8646590ceab3349a40eacca6835',\n",
              " 'yes-79c8ae6a-459b-11ef-8594-9801a7964a15_jpg.rf.d4cc74926eee1c08c50e4c1caebe7aad',\n",
              " 'thanks-6ffa9d58-459b-11ef-8594-9801a7964a15_jpg.rf.2284f04c2a818d752148f39475d68de3',\n",
              " 'yes-8a020bdc-459b-11ef-8594-9801a7964a15_jpg.rf.d1311732e49d1d83e8b40792d784d566',\n",
              " 'iloveyou-a8e838aa-459b-11ef-8594-9801a7964a15_jpg.rf.a62226b8cf8b22820b3456cb72146b61',\n",
              " 'no-9a168f48-459b-11ef-8594-9801a7964a15_jpg.rf.fe77c58b32264f341e1f60caef21d821',\n",
              " 'hello-5ea2fa28-459b-11ef-8594-9801a7964a15_jpg.rf.e419a2f5c2328712b46dce73ce3fed10',\n",
              " 'yes-80067cf8-459b-11ef-8594-9801a7964a15_jpg.rf.2df821cdc97cbac3e76cc96460e6d600',\n",
              " 'hello-54b49bca-459b-11ef-8594-9801a7964a15_jpg.rf.6519935cd66df4c0375cb3caddf8ec26',\n",
              " 'hello-50faa47a-459b-11ef-8594-9801a7964a15_jpg.rf.a404baa56e128b738b60c956823dcc3c',\n",
              " 'iloveyou-b2fb85fe-459b-11ef-8594-9801a7964a15_jpg.rf.10ba03196a6b2a8816348c463f4f0fd1',\n",
              " 'no-9c976684-459b-11ef-8594-9801a7964a15_jpg.rf.5efa3e307f912e53ab408d0e2f83b628',\n",
              " 'yes-8b432148-459b-11ef-8594-9801a7964a15_jpg.rf.492b661dc9422fbb01994020e25c8f0b',\n",
              " 'yes-850196f2-459b-11ef-8594-9801a7964a15_jpg.rf.12d03776291b0c790cb044c6062e9623',\n",
              " 'iloveyou-b7f903ce-459b-11ef-8594-9801a7964a15_jpg.rf.d462fbef339179a7675fd7aae814ace1',\n",
              " 'yes-8a020bdc-459b-11ef-8594-9801a7964a15_jpg.rf.3403a3d933aa9fbc8fefdd72b479df56',\n",
              " 'yes-864121ae-459b-11ef-8594-9801a7964a15_jpg.rf.989794a59cd4e51f86794dcd5168c25c',\n",
              " 'iloveyou-b1ba006c-459b-11ef-8594-9801a7964a15_jpg.rf.7e437c09d81236310c7675befc19e666',\n",
              " 'yes-7ec6f2b4-459b-11ef-8594-9801a7964a15_jpg.rf.708828ea3ce1154d1aa398db31c9d132',\n",
              " 'hello-5721e32c-459b-11ef-8594-9801a7964a15_jpg.rf.10c3c9774b80ddd89b4010ee3403fa01',\n",
              " 'no-9f0f7d84-459b-11ef-8594-9801a7964a15_jpg.rf.45e41c305b819d3a06597c6d3d1d594e',\n",
              " 'iloveyou-acadddd2-459b-11ef-8594-9801a7964a15_jpg.rf.1ce1eec1aef5c33a287a5c9562a977a4',\n",
              " 'yes-864121ae-459b-11ef-8594-9801a7964a15_jpg.rf.67e70f3c8fe75d2bcbf34a8bbd23e2cd',\n",
              " 'yes-8282329c-459b-11ef-8594-9801a7964a15_jpg.rf.4e6b092ffa36d29c5261a070d4867e02',\n",
              " 'hello-5721e32c-459b-11ef-8594-9801a7964a15_jpg.rf.d21f740d9fde06832681ceb64a8fb2ab',\n",
              " 'iloveyou-ab6839c2-459b-11ef-8594-9801a7964a15_jpg.rf.fd5fbf24dc8c705fec3bf8092cd97efe',\n",
              " 'no-9b57294e-459b-11ef-8594-9801a7964a15_jpg.rf.0cf23b11c81e8e7bb13544f8e2cbf844',\n",
              " 'no-96574dac-459b-11ef-8594-9801a7964a15_jpg.rf.58450598b9aac10fd0c4a6f56d59d81e',\n",
              " 'no-98d5ec00-459b-11ef-8594-9801a7964a15_jpg.rf.5f2973bb5a1927769c078dd582717a2e',\n",
              " 'yes-850196f2-459b-11ef-8594-9801a7964a15_jpg.rf.349ea95769643d216151359a995052cc',\n",
              " 'hello-5ae2055a-459b-11ef-8594-9801a7964a15_jpg.rf.d5725146b9a766d397f4aff3526f5b86',\n",
              " 'iloveyou-ab6839c2-459b-11ef-8594-9801a7964a15_jpg.rf.2719c2d4d9477b4e3ae4a5734e1cb20f',\n",
              " 'iloveyou-aa292eae-459b-11ef-8594-9801a7964a15_jpg.rf.4d88400ec091db7fe482fdee491182dd',\n",
              " 'thanks-73bacfa8-459b-11ef-8594-9801a7964a15_jpg.rf.6b13d9df401bba06cb75c6d61412e11e',\n",
              " 'iloveyou-a8e838aa-459b-11ef-8594-9801a7964a15_jpg.rf.3770d392b39ce2ebfb3252d7bea73cc5',\n",
              " 'hello-58623656-459b-11ef-8594-9801a7964a15_jpg.rf.95d3446155825c0894d2331c18c9415d',\n",
              " 'hello-5ae2055a-459b-11ef-8594-9801a7964a15_jpg.rf.5c901b839f02850749bc6e46d04000cc',\n",
              " 'iloveyou-acadddd2-459b-11ef-8594-9801a7964a15_jpg.rf.2a4ff356b192242cfe3576838fa11495',\n",
              " 'hello-50faa47a-459b-11ef-8594-9801a7964a15_jpg.rf.03e425994c20b4c687b501a6f4ed2913',\n",
              " 'hello-55eb17d0-459b-11ef-8594-9801a7964a15_jpg.rf.cf17dffa3004063f031b750be0ba73c3',\n",
              " 'yes-7ec6f2b4-459b-11ef-8594-9801a7964a15_jpg.rf.3af05ea52588542fee0f103a67519888',\n",
              " 'hello-58623656-459b-11ef-8594-9801a7964a15_jpg.rf.0125f564a3e8c038291988cb5fcae067',\n",
              " 'hello-55eb17d0-459b-11ef-8594-9801a7964a15_jpg.rf.0c482503ab07c392f74b15969ec57b8a',\n",
              " 'thanks-65f4f466-459b-11ef-8594-9801a7964a15_jpg.rf.21328616815666e8b2ca3ad36b23ec9d',\n",
              " 'yes-8a020bdc-459b-11ef-8594-9801a7964a15_jpg.rf.63f929921172c9150ffc6e127717feea',\n",
              " 'iloveyou-aa292eae-459b-11ef-8594-9801a7964a15_jpg.rf.5e65afade2c60461c9eb7013497a6c44',\n",
              " 'no-9dce4ab8-459b-11ef-8594-9801a7964a15_jpg.rf.5a93063c58f9a466eb384b8685c8624c',\n",
              " 'iloveyou-aa292eae-459b-11ef-8594-9801a7964a15_jpg.rf.56370dbe9588153d2432d0a46e4da91c',\n",
              " 'no-96574dac-459b-11ef-8594-9801a7964a15_jpg.rf.ade124e643cd29d32197f2c572fc494e',\n",
              " 'yes-79c8ae6a-459b-11ef-8594-9801a7964a15_jpg.rf.3766c0b46e89c838dc865e74df900b5d',\n",
              " 'hello-54b49bca-459b-11ef-8594-9801a7964a15_jpg.rf.3a0b7718d6a1fb0d36c484e91fad9619',\n",
              " 'no-901a5df8-459b-11ef-8594-9801a7964a15_jpg.rf.1457f743b5dd5e6248db2ce3a2b5821f',\n",
              " 'thanks-6ffa9d58-459b-11ef-8594-9801a7964a15_jpg.rf.07a30f4c700f690eb2db619f40ee1f37',\n",
              " 'thanks-6d786808-459b-11ef-8594-9801a7964a15_jpg.rf.2cf028d8b1a6efc96c4f70c76e51861f',\n",
              " 'iloveyou-b2fb85fe-459b-11ef-8594-9801a7964a15_jpg.rf.f8622961b3f6eac4b5a523b9bd8a1314',\n",
              " 'hello-54b49bca-459b-11ef-8594-9801a7964a15_jpg.rf.213dade87cf68c767c567b64f8427b2b',\n",
              " 'iloveyou-b1ba006c-459b-11ef-8594-9801a7964a15_jpg.rf.83a7850d011122b49c67380c93648109',\n",
              " 'yes-8282329c-459b-11ef-8594-9801a7964a15_jpg.rf.9da9f5f76231c57dc3525fda67359acf',\n",
              " 'yes-8282329c-459b-11ef-8594-9801a7964a15_jpg.rf.6d51ca60c6e9f0cd5ed4383f79e368e9',\n",
              " 'yes-88c1b79a-459b-11ef-8594-9801a7964a15_jpg.rf.61d619833657aeda0bb2f7108869f169',\n",
              " 'no-96574dac-459b-11ef-8594-9801a7964a15_jpg.rf.bc8b381e4a7a39456ba90381339c12ee',\n",
              " 'no-901a5df8-459b-11ef-8594-9801a7964a15_jpg.rf.f64f6312ac997ea48fb175dfee18d0bd',\n",
              " 'no-9dce4ab8-459b-11ef-8594-9801a7964a15_jpg.rf.6ad307bc38c80e1265ce8f4424e0ef37',\n",
              " 'thanks-74fa00aa-459b-11ef-8594-9801a7964a15_jpg.rf.47cdbfe6650e6012c6e0f18c15fa4200',\n",
              " 'yes-8b432148-459b-11ef-8594-9801a7964a15_jpg.rf.cd2d526f7c3b3e68305844576421eb71',\n",
              " 'no-9f0f7d84-459b-11ef-8594-9801a7964a15_jpg.rf.89803ce54d460a581af5e2d1e649f792',\n",
              " 'yes-80067cf8-459b-11ef-8594-9801a7964a15_jpg.rf.b520556fa6818c34499fa8c3671cf7b2',\n",
              " 'thanks-6ffa9d58-459b-11ef-8594-9801a7964a15_jpg.rf.c1e59791b57de1f1e6cba1fda1d02062',\n",
              " 'yes-7ec6f2b4-459b-11ef-8594-9801a7964a15_jpg.rf.38929b2e3aedf212cf9ee16f4c100211',\n",
              " 'hello-58623656-459b-11ef-8594-9801a7964a15_jpg.rf.9ec4af44af6c9d38e0659e7f3e613b63',\n",
              " 'thanks-65f4f466-459b-11ef-8594-9801a7964a15_jpg.rf.3cccc2b26535ed0ead40b10d32f7a396',\n",
              " 'no-9294a66a-459b-11ef-8594-9801a7964a15_jpg.rf.0712f7e08b16f3b3dca387e4e2231732',\n",
              " 'hello-5ea2fa28-459b-11ef-8594-9801a7964a15_jpg.rf.e0d1dfa5adb3092656611cca7724ee4c',\n",
              " 'no-9a168f48-459b-11ef-8594-9801a7964a15_jpg.rf.509bff5379a2fb2de161a05c24d774d2',\n",
              " 'yes-850196f2-459b-11ef-8594-9801a7964a15_jpg.rf.ddbb2494ead91101601491a084abd905',\n",
              " 'iloveyou-b7f903ce-459b-11ef-8594-9801a7964a15_jpg.rf.59e7f4322dc7605c99b06d90f517446c',\n",
              " 'thanks-65f4f466-459b-11ef-8594-9801a7964a15_jpg.rf.1103cb49d620927558bbffc1fd261105',\n",
              " 'hello-50faa47a-459b-11ef-8594-9801a7964a15_jpg.rf.c70a2b49680ac1a804ef0b74c3296996',\n",
              " 'thanks-74fa00aa-459b-11ef-8594-9801a7964a15_jpg.rf.deae1be873788083f7af8a20e144abd4',\n",
              " 'thanks-64b3df36-459b-11ef-8594-9801a7964a15_jpg.rf.b115886a3c4110887d27a8cadc9580bf',\n",
              " 'hello-55eb17d0-459b-11ef-8594-9801a7964a15_jpg.rf.cfa48fc5870e1bbb30b7d8abd6f9af95',\n",
              " 'no-9515fc72-459b-11ef-8594-9801a7964a15_jpg.rf.a4d2c4b7c6572509d33967bf96eeed46',\n",
              " 'thanks-64b3df36-459b-11ef-8594-9801a7964a15_jpg.rf.3545fbf3f0a640e62cf5704905227253',\n",
              " 'yes-864121ae-459b-11ef-8594-9801a7964a15_jpg.rf.c1066d73d18ff3a3e09b2771085fc4a7',\n",
              " 'no-9294a66a-459b-11ef-8594-9801a7964a15_jpg.rf.7a6cdb1a0405362a7c606813b70ac706',\n",
              " 'iloveyou-b2fb85fe-459b-11ef-8594-9801a7964a15_jpg.rf.65e08a5b5602ad33e5e91134e72e2399']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "iss = os.listdir('/content/Game_unity_Detect-1/train/labels')\n",
        "for i in range(len(iss)):\n",
        "  with open(\"/content/Game_unity_Detect-1/train/labels/\"+ iss[i]) as f:\n",
        "\n",
        "    for line in f:\n",
        "        data.append([float(x) for x in line.split() if x != 1 and x!=0 and x!=2 and x!=3 and x!= 4])"
      ],
      "metadata": {
        "id": "nUfFX8-zCF_7"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGsjh16fF0oO",
        "outputId": "587b9eca-5dab-4c9b-ed07-b7eef2eaa841"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.0, 0.7234375, 0.49140625, 0.290625, 0.29375]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "XMin = []\n",
        "XMax = []\n",
        "YMin = []\n",
        "YMax = []\n",
        "for i in range(len(data)):\n",
        "  XMin.append(data[i][1])\n",
        "  XMax.append(data[i][2])\n",
        "  YMin.append(data[i][3])\n",
        "  YMax.append(data[i][4])"
      ],
      "metadata": {
        "id": "eOWpnqhIFVLQ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(XMax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J1DB8w0GRZy",
        "outputId": "d1000a05-cae9-43b0-a068-e506102e84b1"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "123"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "res = []\n",
        "for i in range(len(imgs)):\n",
        "  res.append(re.match('.*?(?=\\-)', imgs[i]).group(0))"
      ],
      "metadata": {
        "id": "haeTre5-7qfi"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cols"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "XWCjjtmsGfzS",
        "outputId": "a83d0b53-8a67-4c9d-9aee-f11350ea0fe0"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               ImageID LabelName      XMin  \\\n",
              "0    no-98d5ec00-459b-11ef-8594-9801a7964a15_jpg.rf...        no  0.723437   \n",
              "1    no-9c976684-459b-11ef-8594-9801a7964a15_jpg.rf...        no  0.783594   \n",
              "2    iloveyou-adefd920-459b-11ef-8594-9801a7964a15_...  iloveyou  0.503125   \n",
              "3    hello-5721e32c-459b-11ef-8594-9801a7964a15_jpg...     hello  0.351562   \n",
              "4    yes-83c24ff2-459b-11ef-8594-9801a7964a15_jpg.r...       yes  0.491406   \n",
              "..                                                 ...       ...       ...   \n",
              "118  no-9515fc72-459b-11ef-8594-9801a7964a15_jpg.rf...        no  0.649219   \n",
              "119  thanks-64b3df36-459b-11ef-8594-9801a7964a15_jp...    thanks  0.650000   \n",
              "120  yes-864121ae-459b-11ef-8594-9801a7964a15_jpg.r...       yes  0.531250   \n",
              "121  no-9294a66a-459b-11ef-8594-9801a7964a15_jpg.rf...        no  0.225781   \n",
              "122  iloveyou-b2fb85fe-459b-11ef-8594-9801a7964a15_...  iloveyou  0.544531   \n",
              "\n",
              "         XMax      YMin      YMax  \n",
              "0    0.491406  0.290625  0.293750  \n",
              "1    0.242188  0.185938  0.289062  \n",
              "2    0.208594  0.181250  0.311719  \n",
              "3    0.545312  0.318750  0.535937  \n",
              "4    0.763281  0.234375  0.340625  \n",
              "..        ...       ...       ...  \n",
              "118  0.897656  0.201563  0.198437  \n",
              "119  0.537500  0.292187  0.523438  \n",
              "120  0.671094  0.345313  0.614062  \n",
              "121  0.703125  0.209375  0.314063  \n",
              "122  0.618750  0.173437  0.509375  \n",
              "\n",
              "[123 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-937c0814-4366-42c8-b0fd-cea61ab5f86d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageID</th>\n",
              "      <th>LabelName</th>\n",
              "      <th>XMin</th>\n",
              "      <th>XMax</th>\n",
              "      <th>YMin</th>\n",
              "      <th>YMax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no-98d5ec00-459b-11ef-8594-9801a7964a15_jpg.rf...</td>\n",
              "      <td>no</td>\n",
              "      <td>0.723437</td>\n",
              "      <td>0.491406</td>\n",
              "      <td>0.290625</td>\n",
              "      <td>0.293750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>no-9c976684-459b-11ef-8594-9801a7964a15_jpg.rf...</td>\n",
              "      <td>no</td>\n",
              "      <td>0.783594</td>\n",
              "      <td>0.242188</td>\n",
              "      <td>0.185938</td>\n",
              "      <td>0.289062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>iloveyou-adefd920-459b-11ef-8594-9801a7964a15_...</td>\n",
              "      <td>iloveyou</td>\n",
              "      <td>0.503125</td>\n",
              "      <td>0.208594</td>\n",
              "      <td>0.181250</td>\n",
              "      <td>0.311719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hello-5721e32c-459b-11ef-8594-9801a7964a15_jpg...</td>\n",
              "      <td>hello</td>\n",
              "      <td>0.351562</td>\n",
              "      <td>0.545312</td>\n",
              "      <td>0.318750</td>\n",
              "      <td>0.535937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yes-83c24ff2-459b-11ef-8594-9801a7964a15_jpg.r...</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.491406</td>\n",
              "      <td>0.763281</td>\n",
              "      <td>0.234375</td>\n",
              "      <td>0.340625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>no-9515fc72-459b-11ef-8594-9801a7964a15_jpg.rf...</td>\n",
              "      <td>no</td>\n",
              "      <td>0.649219</td>\n",
              "      <td>0.897656</td>\n",
              "      <td>0.201563</td>\n",
              "      <td>0.198437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>thanks-64b3df36-459b-11ef-8594-9801a7964a15_jp...</td>\n",
              "      <td>thanks</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.292187</td>\n",
              "      <td>0.523438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>yes-864121ae-459b-11ef-8594-9801a7964a15_jpg.r...</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.531250</td>\n",
              "      <td>0.671094</td>\n",
              "      <td>0.345313</td>\n",
              "      <td>0.614062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>no-9294a66a-459b-11ef-8594-9801a7964a15_jpg.rf...</td>\n",
              "      <td>no</td>\n",
              "      <td>0.225781</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.209375</td>\n",
              "      <td>0.314063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>iloveyou-b2fb85fe-459b-11ef-8594-9801a7964a15_...</td>\n",
              "      <td>iloveyou</td>\n",
              "      <td>0.544531</td>\n",
              "      <td>0.618750</td>\n",
              "      <td>0.173437</td>\n",
              "      <td>0.509375</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>123 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-937c0814-4366-42c8-b0fd-cea61ab5f86d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-937c0814-4366-42c8-b0fd-cea61ab5f86d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-937c0814-4366-42c8-b0fd-cea61ab5f86d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-672f6650-c7f0-4c63-82a1-4ee589351814\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-672f6650-c7f0-4c63-82a1-4ee589351814')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-672f6650-c7f0-4c63-82a1-4ee589351814 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_cols",
              "summary": "{\n  \"name\": \"df_cols\",\n  \"rows\": 123,\n  \"fields\": [\n    {\n      \"column\": \"ImageID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 123,\n        \"samples\": [\n          \"yes-80067cf8-459b-11ef-8594-9801a7964a15_jpg.rf.a4f9ba0b4f8df17b15404d90708a3926\",\n          \"hello-54b49bca-459b-11ef-8594-9801a7964a15_jpg.rf.6519935cd66df4c0375cb3caddf8ec26\",\n          \"iloveyou-b2fb85fe-459b-11ef-8594-9801a7964a15_jpg.rf.10ba03196a6b2a8816348c463f4f0fd1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LabelName\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"iloveyou\",\n          \"thanks\",\n          \"hello\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"XMin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16083852097515214,\n        \"min\": 0.2046875,\n        \"max\": 0.80078125,\n        \"num_unique_values\": 109,\n        \"samples\": [\n          0.6578125,\n          0.70859375,\n          0.49140625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"XMax\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17945514668437795,\n        \"min\": 0.178125,\n        \"max\": 0.90703125,\n        \"num_unique_values\": 105,\n        \"samples\": [\n          0.54765625,\n          0.61328125,\n          0.31640625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"YMin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10411026353484086,\n        \"min\": 0.1140625,\n        \"max\": 0.553125,\n        \"num_unique_values\": 97,\n        \"samples\": [\n          0.27109375,\n          0.275,\n          0.29453125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"YMax\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1271106268395683,\n        \"min\": 0.175,\n        \"max\": 0.6859375,\n        \"num_unique_values\": 105,\n        \"samples\": [\n          0.48125,\n          0.4765625,\n          0.434375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_cols = pd.DataFrame({'ImageID': idx, 'LabelName': res, 'XMin': XMin, 'XMax': XMax, 'YMin': YMin, 'YMax': YMax})"
      ],
      "metadata": {
        "id": "7zZRsEcC7qjZ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_snippets import *\n",
        "\n",
        "\n",
        "label2target = {l:t+1 for t,l in enumerate(df_cols['LabelName'].unique())}\n",
        "label2target['background'] = 0\n",
        "target2label = {t:l for l,t in label2target.items()}\n",
        "background_class = label2target['background']\n",
        "num_classes = len(label2target)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "import collections, os, torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "normalize = transforms.Normalize(\n",
        "    mean=[0.485, 0.456, 0.406],\n",
        "    std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "denormalize = transforms.Normalize(\n",
        "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n",
        "    std=[1/0.229, 1/0.224, 1/0.255])\n",
        "\n",
        "def preprocess_image(img):\n",
        "    img = torch.tensor(img).permute(2,0,1)\n",
        "    img = normalize(img)\n",
        "    return img.to(device).float()\n",
        "\n",
        "class OpenDataset(torch.utils.data.Dataset):\n",
        "    w, h = 300, 300\n",
        "    def __init__(self, df, image_dir='/content/Game_unity_Detect-1/train/images'):\n",
        "        self.image_dir = image_dir\n",
        "        self.files = glob.glob(self.image_dir+'/*')\n",
        "        self.df = df\n",
        "        self.image_infos = df.ImageID.unique()\n",
        "        logger.info(f'{len(self)} items loaded')\n",
        "\n",
        "    def __getitem__(self, ix):\n",
        "        # load images and masks\n",
        "        image_id = self.image_infos[ix]\n",
        "        img_path = find(image_id, self.files)\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        img = np.array(img.resize((self.w, self.h), resample=Image.BILINEAR))/255.\n",
        "        data = df_cols[df_cols['ImageID'] == image_id]\n",
        "        labels = data['LabelName'].values.tolist()\n",
        "        data = data[['XMin','YMin','XMax','YMax']].values\n",
        "        data[:,[0,2]] *= self.w\n",
        "        data[:,[1,3]] *= self.h\n",
        "        boxes = data.astype(np.uint32).tolist() # convert to absolute coordinates\n",
        "        return img, boxes, labels\n",
        "    def collate_fn(self, batch):\n",
        "        images, boxes, labels = [], [], []\n",
        "        for item in batch:\n",
        "            img, image_boxes, image_labels = item\n",
        "            img = preprocess_image(img)[None]\n",
        "            images.append(img)\n",
        "            boxes.append(torch.tensor(image_boxes).float().to(device)/300.)\n",
        "            labels.append(torch.tensor([label2target[c] for c in image_labels]).long().to(device))\n",
        "        images = torch.cat(images).to(device)\n",
        "        return images, boxes, labels\n",
        "    def __len__(self):\n",
        "        return len(self.image_infos)\n",
        ""
      ],
      "metadata": {
        "id": "XKBh9WoaCfSP"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "trn_ids, val_ids = train_test_split(df_cols.ImageID.unique(), test_size=0.1, random_state=99)\n",
        "trn_df, val_df = df_cols[df_cols['ImageID'].isin(trn_ids)], df_cols[df_cols['ImageID'].isin(val_ids)]\n",
        "len(trn_df), len(val_df)\n",
        "\n",
        "train_ds = OpenDataset(trn_df)\n",
        "test_ds = OpenDataset(val_df)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=2, collate_fn=train_ds.collate_fn, drop_last=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=2, collate_fn=test_ds.collate_fn, drop_last=True)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "G4fgbGrCG8bC",
        "outputId": "ffc5a20e-288a-4102-db43-3c0ba30554f4"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[08/01/24 18:23:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[2;33mINFO    \u001b[0m \u001b[1;36m110\u001b[0m items loaded                                                                                    \u001b]8;id=785477;file://<ipython-input-99-ce8baa879414>:40\u001b\\\u001b[2m<ipython-input-99-ce8baa879414>\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=874056;file://<ipython-input-99-ce8baa879414>:40#__init__:40\u001b\\\u001b[2m__init__:40\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[08/01/24 18:23:00] </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">INFO    </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">110</span> items loaded                                                                                    <a href=\"file://<ipython-input-99-ce8baa879414>:40\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-99-ce8baa879414&gt;</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://<ipython-input-99-ce8baa879414>:40#__init__:40\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__:40</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[2;33mINFO    \u001b[0m \u001b[1;36m13\u001b[0m items loaded                                                                                     \u001b]8;id=30677;file://<ipython-input-99-ce8baa879414>:40\u001b\\\u001b[2m<ipython-input-99-ce8baa879414>\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=953818;file://<ipython-input-99-ce8baa879414>:40#__init__:40\u001b\\\u001b[2m__init__:40\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">INFO    </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> items loaded                                                                                     <a href=\"file://<ipython-input-99-ce8baa879414>:40\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-99-ce8baa879414&gt;</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://<ipython-input-99-ce8baa879414>:40#__init__:40\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__:40</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from torch_snippets import *"
      ],
      "metadata": {
        "id": "ixZDNoICCfXw"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_batch(inputs, model, criterion, optimizer):\n",
        "    model.train()\n",
        "    N = len(train_loader)\n",
        "    images, boxes, labels = inputs\n",
        "    _regr, _clss = model(images)\n",
        "    loss = criterion(_regr, _clss, boxes, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate_batch(inputs, model, criterion):\n",
        "    model.eval()\n",
        "    images, boxes, labels = inputs\n",
        "    _regr, _clss = model(images)\n",
        "    loss = criterion(_regr, _clss, boxes, labels)\n",
        "    return loss\n",
        ""
      ],
      "metadata": {
        "id": "0EgMAOmx7hBv"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from model import SSD300, MultiBoxLoss\n",
        "#from torch import SSD300, MultiBoxLoss\n",
        "from detect import *\n",
        "import torch\n",
        "#model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd').cuda()\n",
        "\n",
        "n_epochs = 3\n",
        "\n",
        "model = SSD300(num_classes, device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "criterion = MultiBoxLoss(priors_cxcy=model.priors_cxcy, device=device)\n",
        "\n",
        "log = Report(n_epochs=n_epochs)\n",
        "logs_to_print = 5\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chKVutDzHvyn",
        "outputId": "a61317cd-68b6-4685-b10e-bb477fa44f25"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded base model.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "size_average and reduce args will be deprecated, please use reduction='none' instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "!pip install -q torch_snippets\n",
        "!git clone https://github.com/sizhky/ssd-utils/\n",
        "%cd ssd-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfCW5Ex7Hv2o",
        "outputId": "b04ff6fe-50af-449b-cb6f-611f30a74775"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ssd-utils'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 9 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (9/9), 13.65 KiB | 2.28 MiB/s, done.\n",
            "/content/ssd-utils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epochs):\n",
        "    _n = len(train_loader)\n",
        "    for ix, inputs in enumerate(train_loader):\n",
        "        loss = train_batch(inputs, model, criterion, optimizer)\n",
        "        pos = (epoch + (ix+1)/_n)\n",
        "        log.record(pos, trn_loss=loss.item(), end='\\r')\n",
        "\n",
        "    _n = len(test_loader)\n",
        "    for ix,inputs in enumerate(test_loader):\n",
        "        loss = validate_batch(inputs, model, criterion)\n",
        "        pos = (epoch + (ix+1)/_n)\n",
        "        log.record(pos, val_loss=loss.item(), end='\\r')\n",
        "\n",
        "\n",
        "image_paths = Glob(f'/content/Game_unity_Detect-1/train/images/*')\n",
        "image_id = choose(test_ds.image_infos)\n",
        "img_path = find(image_id, test_ds.files)\n",
        "original_image = Image.open(img_path, mode='r')\n",
        "original_image = original_image.convert('RGB')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPkP3m29Hv8X",
        "outputId": "15f198a5-0575-4486-8941-4dd69d9dc0e5"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 3.000  val_loss: 7.046  (1464.72s - 0.00s remaining)"
          ]
        }
      ]
    }
  ]
}