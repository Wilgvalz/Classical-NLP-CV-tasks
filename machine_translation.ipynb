{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb07b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "from pickle import dump\n",
    "\n",
    "def load_docum(filename):\n",
    "    file = open(filename, mode = 'rt', encoding = 'utf-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bedecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sentences(doc):\n",
    "    return doc.strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48715afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_lenghts(sentences):\n",
    "    lenghts = [len(s.split()) for s in sentences]\n",
    "    return min(lenghts), max(lenghts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4594c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string \n",
    "import unicodedata\n",
    "def clean_lines(lines):\n",
    "    cleaned = list()\n",
    "    re_print = re.compile('[^%s]'% re.escape(string.printable)) \n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for line in lines:\n",
    "        line = unicodedata.normalize('NFD', line).encode('ascii', 'ignore')\n",
    "        line = line.decode('UTF-8')\n",
    "        line = line.split()\n",
    "        line = [word.lower() for word in line]\n",
    "        line = [word.translate(table) for word in line] \n",
    "        line = [re_print.sub('', w) for w in line]\n",
    "        line = [word for word in line if word.isalpha()]\n",
    "        cleaned.append(' '.join(line))\n",
    "    return cleaned \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37b32404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English data: sentences=1909115, min=0, max=668\n",
      "English.pkl saved\n"
     ]
    }
   ],
   "source": [
    "filename = 'europarl-v7.it-en.en'\n",
    "doc = load_docum(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lenghts(sentences)\n",
    "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
    "cleanf = clean_lines(sentences)\n",
    "filename = 'English.pkl'\n",
    "outfile = open(filename, 'wb')\n",
    "pickle.dump(cleanf, outfile)\n",
    "outfile.close()\n",
    "print(filename, 'saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8596e3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italian data: sentences=1909115, min=0, max=558\n",
      "Italian.pkl saved\n"
     ]
    }
   ],
   "source": [
    "filename = 'europarl-v7.it-en.it'\n",
    "doc = load_docum(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lenghts(sentences)\n",
    "print('Italian data: sentences=%d, min=%d, max=%d' % (len(sentences),\n",
    "minlen, maxlen))\n",
    "cleanf = clean_lines(sentences)\n",
    "filename = 'Italian.pkl'\n",
    "outfile = open(filename, 'wb')\n",
    "pickle.dump(cleanf, outfile)\n",
    "outfile.close()\n",
    "print(filename, 'saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e46aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5201291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "from pickle import dump\n",
    "from collections import Counter \n",
    "def load_clean_sentences(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    "def save_clean_sentences(sentences, filename):\n",
    "    dump(sentences, open(filename, 'wb'))\n",
    "    print('Saved: %s'%filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf4a7f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vocab(lines):\n",
    "    vocab = Counter()\n",
    "    for line in lines:\n",
    "        tokens = line.split()\n",
    "        vocab.update(tokens)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66545adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_vocab(vocab, min_occurrence):\n",
    "    tokens = [k for k,c in vocab.items() if c >= min_occurrence]\n",
    "    return set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e916aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataset(lines, vocab):\n",
    "    new_lines = list()\n",
    "    for line in lines:\n",
    "        new_tokens = list()\n",
    "        for token in line.split():\n",
    "            if token in vocab:\n",
    "                new_tokens.append(token)\n",
    "            else:\n",
    "                new_tokens.append('unkn')\n",
    "        new_line = ' '.join(new_tokens)\n",
    "        new_lines.append(new_line)\n",
    "    return new_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f70a7d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary: 104655\n",
      "New English Vocabulary: 41564\n",
      "Saved: english_vocab.pkl\n",
      "line 0 : resumption of the session\n",
      "line 1 : i declare resumed the session of the european parliament adjourned on friday december and i would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period\n",
      "line 2 : although as you will have seen the dreaded millennium bug failed to materialise still the people in a number of countries suffered a series of natural disasters that truly were dreadful\n",
      "line 3 : you have requested a debate on this subject in the course of the next few days during this partsession\n",
      "line 4 : in the meantime i should like to observe a minute s silence as a number of members have requested on behalf of all the victims concerned particularly those of the terrible storms in the various countries of the european union\n",
      "line 5 : please rise then for this minute s silence\n",
      "line 6 : the house rose and observed a minute s silence\n",
      "line 7 : madam president on a point of order\n",
      "line 8 : you will be aware from the press and television that there have been a number of bomb explosions and killings in sri lanka\n",
      "line 9 : one of the people assassinated very recently in sri lanka was mr unkn unkn who had visited the european parliament just a few months ago\n"
     ]
    }
   ],
   "source": [
    "filename = 'English.pkl'\n",
    "lines1 = load_clean_sentences(filename)\n",
    "vocab = to_vocab(lines1)\n",
    "print('English Vocabulary: %d' % len(vocab))\n",
    "vocab = trim_vocab(vocab, 5)\n",
    "print('New English Vocabulary: %d' % len(vocab))\n",
    "lines1 = update_dataset(lines1, vocab)\n",
    "filename = 'english_vocab.pkl'\n",
    "save_clean_sentences(lines1, filename)\n",
    "for i in range(10):\n",
    "    print(\"line\",i,\":\",lines1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77599555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italian Vocabulary: 171079\n",
      "New Italian Vocabulary: 67378\n",
      "Saved: italian_vocab.pkl\n",
      "line 0 : ripresa della sessione\n",
      "line 1 : dichiaro ripresa la sessione del parlamento europeo interrotta venerdi dicembre e rinnovo a tutti i miei migliori auguri nella speranza che abbiate trascorso delle buone vacanze\n",
      "line 2 : come avrete avuto modo di constatare il grande baco del millennio non si e materializzato invece i cittadini di alcuni nostri paesi sono stati colpiti da catastrofi naturali di proporzioni davvero terribili\n",
      "line 3 : avete chiesto che si tenesse una discussione su tale tema nei prossimi giorni nel corso della presente tornata\n",
      "line 4 : nel frattempo e mio desiderio come del resto mi e stato chiesto da alcuni colleghi osservare un minuto di silenzio in memoria di tutte le vittime delle tempeste che si sono abbattute sui diversi paesi dell unione europea\n",
      "line 5 : vi invito pertanto ad alzarvi in piedi per osservare appunto un minuto di silenzio\n",
      "line 6 : il parlamento osserva un minuto di silenzio\n",
      "line 7 : signora presidente intervengo per una mozione dordine\n",
      "line 8 : come avra letto sui giornali o sentito alla televisione in sri lanka si sono verificati numerosi assassinii ed esplosioni di ordigni\n",
      "line 9 : una delle vittime piu recenti e stato unkn unkn che qualche mese fa era venuto in visita qui al parlamento europeo\n"
     ]
    }
   ],
   "source": [
    "filename = 'Italian.pkl'\n",
    "lines = load_clean_sentences(filename)\n",
    "vocab = to_vocab(lines)\n",
    "print('Italian Vocabulary: %d' % len(vocab))\n",
    "vocab = trim_vocab(vocab, 5)\n",
    "print('New Italian Vocabulary: %d' % len(vocab))\n",
    "lines = update_dataset(lines, vocab)\n",
    "filename = 'italian_vocab.pkl'\n",
    "save_clean_sentences(lines, filename)\n",
    "for i in range(10):\n",
    "    print(\"line\",i,\":\",lines[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eaabd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d454ece3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>it</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resumption of the session</td>\n",
       "      <td>ripresa della sessione</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i declare resumed the session of the european ...</td>\n",
       "      <td>dichiaro ripresa la sessione del parlamento eu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>although as you will have seen the dreaded mil...</td>\n",
       "      <td>come avrete avuto modo di constatare il grande...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you have requested a debate on this subject in...</td>\n",
       "      <td>avete chiesto che si tenesse una discussione s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in the meantime i should like to observe a min...</td>\n",
       "      <td>nel frattempo e mio desiderio come del resto m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>madame president the people of austria have sp...</td>\n",
       "      <td>signora presidente il popolo austriaco si e es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>i believe they gave him of the vote so there i...</td>\n",
       "      <td>credo che egli abbia ottenuto il percento dei ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>your parliament may i suggest madame president...</td>\n",
       "      <td>il suo parlamento signora presidente dovrebbe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>then and only then might you consider if human...</td>\n",
       "      <td>allora e soltanto allora sara possibile decide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>your parliament may consider measures appropri...</td>\n",
       "      <td>a quel punto il suo parlamento potra prendere ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    eng   \n",
       "0                             resumption of the session  \\\n",
       "1     i declare resumed the session of the european ...   \n",
       "2     although as you will have seen the dreaded mil...   \n",
       "3     you have requested a debate on this subject in...   \n",
       "4     in the meantime i should like to observe a min...   \n",
       "...                                                 ...   \n",
       "4995  madame president the people of austria have sp...   \n",
       "4996  i believe they gave him of the vote so there i...   \n",
       "4997  your parliament may i suggest madame president...   \n",
       "4998  then and only then might you consider if human...   \n",
       "4999  your parliament may consider measures appropri...   \n",
       "\n",
       "                                                     it  \n",
       "0                                ripresa della sessione  \n",
       "1     dichiaro ripresa la sessione del parlamento eu...  \n",
       "2     come avrete avuto modo di constatare il grande...  \n",
       "3     avete chiesto che si tenesse una discussione s...  \n",
       "4     nel frattempo e mio desiderio come del resto m...  \n",
       "...                                                 ...  \n",
       "4995  signora presidente il popolo austriaco si e es...  \n",
       "4996  credo che egli abbia ottenuto il percento dei ...  \n",
       "4997  il suo parlamento signora presidente dovrebbe ...  \n",
       "4998  allora e soltanto allora sara possibile decide...  \n",
       "4999  a quel punto il suo parlamento potra prendere ...  \n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'eng': lines1, 'it': lines})\n",
    "df = df[:5000]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c3fd551",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5000):\n",
    "    if len(df['eng'][i])>128:\n",
    "        df['eng'][i] = df['eng'][i][:128]\n",
    "    if len(df['it'][i])>128:\n",
    "        df['it'][i] = df['it'][i][:128]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e986b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = []\n",
    "for i in range(5000):\n",
    "    mc.append({'translation':{'eng':df['eng'][i], 'it':df['it'][i] }})\n",
    "ds = pd.DataFrame(mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b826a3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'eng': 'resumption of the session', 'it': 'ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'eng': 'i declare resumed the session of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'eng': 'although as you will have seen the dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'eng': 'you have requested a debate on this s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'eng': 'in the meantime i should like to obse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>{'eng': 'madame president the people of austri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>{'eng': 'i believe they gave him of the vote s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>{'eng': 'your parliament may i suggest madame ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>{'eng': 'then and only then might you consider...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>{'eng': 'your parliament may consider measures...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            translation\n",
       "0     {'eng': 'resumption of the session', 'it': 'ri...\n",
       "1     {'eng': 'i declare resumed the session of the ...\n",
       "2     {'eng': 'although as you will have seen the dr...\n",
       "3     {'eng': 'you have requested a debate on this s...\n",
       "4     {'eng': 'in the meantime i should like to obse...\n",
       "...                                                 ...\n",
       "4995  {'eng': 'madame president the people of austri...\n",
       "4996  {'eng': 'i believe they gave him of the vote s...\n",
       "4997  {'eng': 'your parliament may i suggest madame ...\n",
       "4998  {'eng': 'then and only then might you consider...\n",
       "4999  {'eng': 'your parliament may consider measures...\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e29d3881",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset \n",
    "from datasets import Dataset\n",
    "dataset_2 = Dataset.from_pandas(ds)\n",
    "train_dataset_2, validation_dataset_2= dataset_2.train_test_split(test_size=0.1).values()\n",
    "import datasets\n",
    "dss = datasets.DatasetDict({\"train\":train_dataset_2,\"test\":validation_dataset_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfa87972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-tc-big-en-it\")\n",
    "prefix = \"translate English to Italian: \"\n",
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "source_lang = \"eng\"\n",
    "target_lang = \"it\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + ex[source_lang] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94c3bccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5926cf85e64f05a61e7468a9dd5c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f7087a222934fccbb0ae11dba462c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 19:46:36.930793: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-05 19:46:36.933675: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-05 19:46:36.942895: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-05 19:46:36.960716: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-05 19:46:36.960741: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-05 19:46:36.972692: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-05 19:46:38.256935: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = dss.map(preprocess_function, batched=True)\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-tc-big-en-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e2a7845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=0.00001,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.001,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8072480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "import numpy as np\n",
    "\n",
    "def post_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "   \n",
    "    decoded_preds, decoded_labels = post_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    dict_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(dict_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7057c8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cff3a4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['WANDB_DISABLED'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a35439d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6000' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6000/6000 20:07, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.965700</td>\n",
       "      <td>1.969931</td>\n",
       "      <td>22.478700</td>\n",
       "      <td>19.472000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.566900</td>\n",
       "      <td>1.979759</td>\n",
       "      <td>22.222600</td>\n",
       "      <td>19.474000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.356300</td>\n",
       "      <td>1.998489</td>\n",
       "      <td>22.670600</td>\n",
       "      <td>19.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.264500</td>\n",
       "      <td>2.013925</td>\n",
       "      <td>22.482700</td>\n",
       "      <td>19.388000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[54421]], 'forced_eos_token_id': 43017}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[54421]], 'forced_eos_token_id': 43017}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[54421]], 'forced_eos_token_id': 43017}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[54421]], 'forced_eos_token_id': 43017}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[54421]], 'forced_eos_token_id': 43017}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[54421]], 'forced_eos_token_id': 43017}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[54421]], 'forced_eos_token_id': 43017}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[54421]], 'forced_eos_token_id': 43017}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[54421]], 'forced_eos_token_id': 43017}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[54421]], 'forced_eos_token_id': 43017}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[54421]], 'forced_eos_token_id': 43017}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[54421]], 'forced_eos_token_id': 43017}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6000, training_loss=1.5139954528808595, metrics={'train_runtime': 1207.8699, 'train_samples_per_second': 14.902, 'train_steps_per_second': 4.967, 'total_flos': 593387194023936.0, 'train_loss': 1.5139954528808595, 'epoch': 4.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "metric = load_metric(\"sacrebleu\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be5d1cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('model_mt.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e6b1967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "model_3 = pd.read_pickle(r'model_mt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5c8bc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('eng_it_data.pkl', 'wb') as f:\n",
    "     pickle.dump(tokenized_datasets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67d0a30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('eng_it_data_nettokenazira.pkl', 'wb') as f:\n",
    "     pickle.dump(dss, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040fca9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4325d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50631b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb48977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
